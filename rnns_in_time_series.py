# -*- coding: utf-8 -*-
"""RNNs in time series.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tblq-ucr5Uj0ZOf8ElMcQ8IhaOaMB-0F

#imports
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras import losses

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
from statsmodels.tsa.arima_model import ARIMA
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import acf, pacf
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error
import itertools

"""#functions"""

def prepare_data(dataFrame: pd.DataFrame, target: str):
    # get target data
    n_cols = 1
    dataset = dataFrame[target]
    dataset = pd.DataFrame(dataset)
    data = dataset.values

    # split into test & train data sizes
    train_size = int(len(data) * 0.75)
    test_size = len(data) - train_size
    #logger.info(f"Train Size: {train_size} Test Size: {test_size}")

    # scale data between (0, 1)
    scaler = MinMaxScaler(feature_range= (0, 1))
    scaled_data = scaler.fit_transform(np.array(data))
    train_data = scaled_data[0:train_size, :]

    # Creating a Training set with 60 time-steps
    x_train = []
    y_train = []
    time_steps = 60
    n_cols = 1

    for i in range(time_steps, len(scaled_data)):
        x_train.append(scaled_data[i-time_steps:i, :n_cols])
        y_train.append(scaled_data[i, :n_cols])

    x_train, y_train = np.array(x_train), np.array(y_train)
    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], n_cols))
    return x_train, y_train, scaler, train_size, test_size, scaled_data

def generate_forecast(scaled_data, train_size) -> (np.array, np.array):
    time_steps = 60
    test_data = scaled_data[train_size - time_steps:, :]

    x_test = []
    y_test = []
    n_cols = 1

    for i in range(time_steps, len(test_data)):
        x_test.append(test_data[i-time_steps:i, 0:n_cols])
        y_test.append(test_data[i, 0:n_cols])
    x_test, y_test = np.array(x_test), np.array(y_test)
    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

    return x_test, y_test

def generate_forecast_v2(dataFrame: pd.DataFrame, target: str) -> (np.array, np.array):
    # get target data
    dataset = dataFrame[target]
    dataset = pd.DataFrame(dataset)
    data = dataset.values

    # split into test & train data sizes. ! Need only to make offset !
    train_size = int(len(data) * 0.05)
    test_size = len(data) - train_size

    # scale data between (0, 1)
    scaler = MinMaxScaler(feature_range= (0, 1))
    scaled_data = scaler.fit_transform(np.array(dataset))
    train_data = scaled_data[0:train_size, :]

    # Creating a Training set with 60 time-steps
    x_train = []
    y_train = []
    time_steps = 60
    n_cols = 1

    for i in range(time_steps, len(scaled_data)):
        x_train.append(scaled_data[i-time_steps:i, :n_cols])
        y_train.append(scaled_data[i, :n_cols])

    x_train, y_train = np.array(x_train), np.array(y_train)
    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], n_cols))

    test_data = scaled_data[train_size - time_steps:, :]

    x_test = []
    y_test = []
    n_cols = 1

    for i in range(time_steps, len(test_data)):
        x_test.append(test_data[i-time_steps:i, 0:n_cols])
        y_test.append(test_data[i, 0:n_cols])
    x_test, y_test = np.array(x_test), np.array(y_test)
    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

    return x_test, y_test, train_size

# def show_type_1(data: pd.DataFrame) -> None:
#     plt.figure(figsize=(26, 18))
#     colors = ['#FF7F50', '#DDA0DD', '#66CDAA', '#BC8F8F']

#     for i, j in enumerate(data.columns):
#       plt.subplot(len(data.columns) + 1, 1, i + 1)
#       plt.plot(data[j], color=colors[i]);
#       plt.plot(data[j].rolling(30).mean());
#       plt.ylabel(j, fontsize=16)
#       plt.grid()
#     plt.xlabel('Date', fontsize=16)

"""#losses and optimisers"""

mse_loss = tf.keras.losses.MeanSquaredError()
mae_loss = tf.keras.losses.MeanAbsoluteError()
huber_loss = tf.keras.losses.Huber()

adam = tf.keras.optimizers.Adam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07
)

adamw = tf.keras.optimizers.AdamW(
    learning_rate=0.001,
    weight_decay=0.004,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07
    )

"""#data loading

##Delhi Climate
"""

df = pd.read_csv('/content/DailyDelhiClimateTrain.csv')

df_test = pd.read_csv('/content/DailyDelhiClimateTest.csv')

df.date = pd.to_datetime(df.date)
df.set_index('date', inplace=True)

df_test.date = pd.to_datetime(df_test.date)
df_test.set_index('date', inplace=True)

df_test = pd.read_csv('/content/DailyDelhiClimateTest.csv')

df_test.date = pd.to_datetime(df_test.date)
df_test.set_index('date', inplace=True)

# df = df[(df['meantemp'] > 980) & (df['meantemp'] < 1050)]
# data_to_show = df#df.drop('date', axis=1)
# show_type_1(data_to_show)

"""Везде для простоты условимся, что будем предсказывать среднесуточную температуру, так как затем будет проще сравнивать

##Sophist HSE - INVFC_M - месячные показатели инвестиций в основной капитал
"""

df = pd.read_csv('/content/INVFC_M.csv')

# df.date = pd.to_datetime(df_test.date)
# df.set_index('date', inplace=True)

"""##Sophist HSE - CPI_M_CHI - месячные показатели инвестиций в основной капитал

#decomposition
"""

ts_decomposition = seasonal_decompose(x=df['meantemp'], model='additive', period=365)
trend_estimate = ts_decomposition.trend
seasonal_estimate = ts_decomposition.seasonal
residual_estimate = ts_decomposition.resid

plt.figure(figsize=(15,5))
plt.plot(df['meantemp'], label='Original')
plt.legend()

plt.figure(figsize=(15,5))
plt.plot(trend_estimate, label='Trend')
plt.legend()

plt.figure(figsize=(15,5))
plt.plot(seasonal_estimate, label='Seasonal')
plt.legend()

plt.figure(figsize=(15,5))
plt.plot(residual_estimate, label='Residual')
plt.legend()

x_train, y_train, scaler, train_size, test_size, scaled_data = prepare_data(df, "meantemp")

train_size

test_size

scaled_data

"""#Models"""

RMSE_scores = {}
MAE_scores = {}

"""##LSTM"""

model = Sequential([
    LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1)),
    LSTM(units=50, return_sequences=False),
    Dense(units=25),
    Dense(units=1)
])

model.compile(optimizer='adam', loss='mean_squared_error')
history = model.fit(x_train, y_train, epochs= 30, batch_size= 32)

plt.plot(range(0, 30), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

dataset = df["meantemp"]
dataset = pd.DataFrame(dataset)

train = dataset.iloc[:train_size , 0:1]
test = dataset.iloc[train_size: , 0:1]
test['Predictions'] = predictions

plt.figure(figsize= (16, 6))
plt.title('Temperature Prediction', fontsize= 18)
plt.xlabel('Date', fontsize= 18)
plt.ylabel('Temperature', fontsize= 18)
plt.plot(train['meantemp'], linewidth= 3)
plt.plot(test['meantemp'], linewidth= 3)
plt.plot(test["Predictions"], linewidth= 3)
plt.legend(['Train', 'Test', 'Predictions'])

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

# Get Prediction
predictions = model.predict(x_test)

predictions.shape

#inverse predictions scaling
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean(y_test - predictions)**2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

RMSE_scores["LSTM"] = RMSE
MAE_scores["LSTM"] = MAE

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})
preds_acts

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

"""##another LSTM"""

model = Sequential([
    LSTM(units=25, return_sequences=True, input_shape=(x_train.shape[1], 1)),
    LSTM(units=25, return_sequences=False),
    Dense(units=25),
    Dense(units=1)
])

model.compile(optimizer='adam', loss='mean_squared_error')
history = model.fit(x_train, y_train, epochs= 30, batch_size= 32)

plt.plot(range(0, 30), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

dataset = df["meantemp"]
dataset = pd.DataFrame(dataset)

train = dataset.iloc[:train_size , 0:1]
test = dataset.iloc[train_size: , 0:1]
test['Predictions'] = predictions

plt.figure(figsize= (16, 6))
plt.title('Temperature Prediction', fontsize= 18)
plt.xlabel('Date', fontsize= 18)
plt.ylabel('Temperature', fontsize= 18)
plt.plot(train['meantemp'], linewidth= 3)
plt.plot(test['meantemp'], linewidth= 3)
plt.plot(test["Predictions"], linewidth= 3)
plt.legend(['Train', 'Test', 'Predictions'])

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

# Get Prediction
predictions = model.predict(x_test)

predictions.shape

#inverse predictions scaling
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean( y_test - predictions )**2)#.round(2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

RMSE_scores["another_LSTM"] = RMSE
MAE_scores["another_LSTM"] = MAE

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})
preds_acts

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

"""##GRU"""

# Create GRU model
def create_gru(units):
    model = Sequential()

    # Input layer
    model.add(layers.GRU(units = units, return_sequences = True,
    input_shape = [x_train.shape[1], x_train.shape[2]]))
    model.add(layers.Dropout(0.2))

    # Hidden layer
    model.add(layers.GRU(units = units))
    model.add(layers.Dropout(0.2))
    model.add(Dense(units = 1))

    #Compile model
    #model.compile(optimizer='adam',loss='mse')
    return model
model = create_gru(64)

model.compile(optimizer='adam', loss='mean_squared_error')
history = model.fit(x_train, y_train, epochs= 30, batch_size= 32)

plt.plot(range(0, 30), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

dataset = df["meantemp"]
dataset = pd.DataFrame(dataset)

train = dataset.iloc[:train_size , 0:1]
test = dataset.iloc[train_size: , 0:1]
test['Predictions'] = predictions

plt.figure(figsize= (16, 6))
plt.title('Temperature Prediction', fontsize= 18)
plt.xlabel('Date', fontsize= 18)
plt.ylabel('Temperature', fontsize= 18)
plt.plot(train['meantemp'], linewidth= 3)
plt.plot(test['meantemp'], linewidth= 3)
plt.plot(test["Predictions"], linewidth= 3)
plt.legend(['Train', 'Test', 'Predictions'])

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

# Get Prediction
predictions = model.predict(x_test)

predictions.shape

#inverse predictions scaling
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean( y_test - predictions )**2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

RMSE_scores["GRU"] = RMSE
MAE_scores["GRU"] = MAE

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})
preds_acts

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

"""##BiLSTM

bidirectional LSTM
"""

# Create BiLSTM model
def create_bilstm(units):
  model = Sequential()

  # Input layer
  model.add(layers.Bidirectional(
              LSTM(units = units, return_sequences=True),
              input_shape=(x_train.shape[1], x_train.shape[2])))

  # Hidden layer
  model.add(layers.Bidirectional(LSTM(units = units)))
  model.add(Dense(1))

  return model

model = create_bilstm(64)

#Compile model
model.compile(optimizer="adam",loss="mse")

model.compile(optimizer='adam', loss='mean_squared_error')
history = model.fit(x_train, y_train, epochs= 30, batch_size= 32)

plt.plot(range(0, 30), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

dataset = df["meantemp"]
dataset = pd.DataFrame(dataset)

train = dataset.iloc[:train_size , 0:1]
test = dataset.iloc[train_size: , 0:1]
test['Predictions'] = predictions

plt.figure(figsize= (16, 6))
plt.title('Temperature Prediction', fontsize= 18)
plt.xlabel('Date', fontsize= 18)
plt.ylabel('Temperature', fontsize= 18)
plt.plot(train['meantemp'], linewidth= 3)
plt.plot(test['meantemp'], linewidth= 3)
plt.plot(test["Predictions"], linewidth= 3)
plt.legend(['Train', 'Test', 'Predictions'])

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

# Get Prediction
predictions = model.predict(x_test)

predictions.shape

#inverse predictions scaling
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean( y_test - predictions )**2)#.round(2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

RMSE_scores["BiLSTM"] = RMSE
MAE_scores["BiLSTM"] = MAE

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})
preds_acts

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

"""##better parameters BiLSTM"""

#Compile model
model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=0.01),loss="mse")

"""also changed batch_size here"""

history = model.fit(x_train, y_train, epochs= 50, batch_size= 8)

plt.plot(range(0, 50), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

#inverse predictions scaling
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean( y_test - predictions )**2)#.round(2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

RMSE_scores["BiLSTM_new"] = RMSE
MAE_scores["BiLSTM_new"] = MAE

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

"""##stacked LSTM"""

# expected input data shape: (batch_size, timesteps, data_dim)
model = Sequential()
model.add(LSTM(50, return_sequences=True,
               input_shape=(x_train.shape[1], 1)))  # returns a sequence of vectors of dimension 50
model.add(LSTM(50, return_sequences=True))  # returns a sequence of vectors of dimension 50
model.add(LSTM(50))  # return a single vector of dimension 50
model.add(Dense(10))
model.add(Dense(1, activation='softmax'))

#Compile model
model.compile(optimizer='adam',loss="mse")

history = model.fit(x_train, y_train, epochs= 50, batch_size= 32)

plt.plot(range(0, 50), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

#inverse predictions scaling
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean( y_test - predictions )**2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

# RMSE_scores["stacked_LSTM"] = RMSE
# MAE_scores["stacked_LSTM"] = MAE

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

"""#Scores"""

import matplotlib.pyplot as plt

plt.bar(list(RMSE_scores.keys()), RMSE_scores.values(), color='g')
plt.show()

plt.bar(list(MAE_scores.keys()), MAE_scores.values(), color='y')
plt.show()

"""#---Brent oil daily price---

#data loading
"""

df = pd.read_csv('/content/brent_oil_daily.csv')

df.Date = pd.to_datetime(df.Date)
df.set_index('Date', inplace=True)

df

"""train test split"""

# df_test = df[round(len(df)*0.67):]

# len(df_test)

# df = df[:len(df)-len(df_test)]

# len(df)

predicting_col='Price'

"""#decomposition"""

ts_decomposition = seasonal_decompose(x=df[predicting_col], model='additive', period=365)
trend_estimate = ts_decomposition.trend
seasonal_estimate = ts_decomposition.seasonal
residual_estimate = ts_decomposition.resid

plt.figure(figsize=(15,5))
plt.plot(df[predicting_col], label='Original')
plt.legend()

plt.figure(figsize=(15,5))
plt.plot(trend_estimate, label='Trend')
plt.legend()

plt.figure(figsize=(15,5))
plt.plot(seasonal_estimate, label='Seasonal')
plt.legend()

plt.figure(figsize=(15,5))
plt.plot(residual_estimate, label='Residual')
plt.legend()

x_train, y_train, scaler, train_size, test_size, scaled_data = prepare_data(df, predicting_col)

train_size

test_size

scaled_data

"""#Models"""

RMSE_scores = {}
MAE_scores = {}

"""##LSTM"""

model = Sequential([
    LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1)),
    LSTM(units=50, return_sequences=False),
    Dense(units=25),
    Dense(units=1)
])

model.compile(optimizer='adam', loss='mean_squared_error')
history = model.fit(x_train, y_train, epochs= 30, batch_size= 32)

plt.plot(range(0, 30), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

dataset = df[predicting_col]
dataset = pd.DataFrame(dataset)

train = dataset.iloc[:train_size , 0:1]
test = dataset.iloc[train_size: , 0:1]
test['Predictions'] = predictions

plt.figure(figsize= (16, 6))
plt.title('Price Prediction', fontsize= 18)
plt.xlabel('Date', fontsize= 18)
plt.ylabel('Price', fontsize= 18)
plt.plot(train[predicting_col], linewidth= 3)
plt.plot(test[predicting_col], linewidth= 3)
plt.plot(test["Predictions"], linewidth= 3)
plt.legend(['Train', 'Test', 'Predictions'])

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

# Get Prediction
predictions = model.predict(x_test)

predictions.shape

#inverse predictions scaling
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean(y_test - predictions)**2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

RMSE_scores["LSTM"] = RMSE
MAE_scores["LSTM"] = MAE

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})
preds_acts

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

"""##another LSTM"""

model = Sequential([
    LSTM(units=25, return_sequences=True, input_shape=(x_train.shape[1], 1)),
    LSTM(units=25, return_sequences=False),
    Dense(units=25),
    Dense(units=1)
])

model.compile(optimizer='adam', loss='mean_squared_error')
history = model.fit(x_train, y_train, epochs= 30, batch_size= 32)

plt.plot(range(0, 30), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

dataset = df[predicting_col]
dataset = pd.DataFrame(dataset)

train = dataset.iloc[:train_size , 0:1]
test = dataset.iloc[train_size: , 0:1]
test['Predictions'] = predictions

plt.figure(figsize= (16, 6))
plt.title('Price Prediction', fontsize= 18)
plt.xlabel('Date', fontsize= 18)
plt.ylabel('Price', fontsize= 18)
plt.plot(train[predicting_col], linewidth= 3)
plt.plot(test[predicting_col], linewidth= 3)
plt.plot(test["Predictions"], linewidth= 3)
plt.legend(['Train', 'Test', 'Predictions'])

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

# Get Prediction
predictions = model.predict(x_test)

predictions.shape

#inverse predictions scaling
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean( y_test - predictions )**2)#.round(2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

RMSE_scores["another_LSTM"] = RMSE
MAE_scores["another_LSTM"] = MAE

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})
preds_acts

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

"""##GRU"""

# Create GRU model
def create_gru(units):
    model = Sequential()

    # Input layer
    model.add(layers.GRU(units = units, return_sequences = True,
    input_shape = [x_train.shape[1], x_train.shape[2]]))
    model.add(layers.Dropout(0.2))

    # Hidden layer
    model.add(layers.GRU(units = units))
    model.add(layers.Dropout(0.2))
    model.add(Dense(units = 1))

    #Compile model
    #model.compile(optimizer='adam',loss='mse')
    return model
model = create_gru(64)

model.compile(optimizer='adam', loss='mean_squared_error')
history = model.fit(x_train, y_train, epochs= 30, batch_size= 32)

plt.plot(range(0, 30), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

dataset = df[predicting_col]
dataset = pd.DataFrame(dataset)

train = dataset.iloc[:train_size , 0:1]
test = dataset.iloc[train_size: , 0:1]
test['Predictions'] = predictions

plt.figure(figsize= (16, 6))
plt.title('Price Prediction', fontsize= 18)
plt.xlabel('Date', fontsize= 18)
plt.ylabel('Price', fontsize= 18)
plt.plot(train[predicting_col], linewidth= 3)
plt.plot(test[predicting_col], linewidth= 3)
plt.plot(test["Predictions"], linewidth= 3)
plt.legend(['Train', 'Test', 'Predictions'])

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

# Get Prediction
predictions = model.predict(x_test)

predictions.shape

#inverse predictions scaling
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean( y_test - predictions )**2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

RMSE_scores["GRU"] = RMSE
MAE_scores["GRU"] = MAE

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})
preds_acts

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

"""##BiLSTM

bidirectional LSTM
"""

# Create BiLSTM model
def create_bilstm(units):
  model = Sequential()

  # Input layer
  model.add(layers.Bidirectional(
              LSTM(units = units, return_sequences=True),
              input_shape=(x_train.shape[1], x_train.shape[2])))

  # Hidden layer
  model.add(layers.Bidirectional(LSTM(units = units)))
  model.add(Dense(1))

  return model

model = create_bilstm(64)

#Compile model
model.compile(optimizer="adam",loss="mse")

model.compile(optimizer='adam', loss='mean_squared_error')
history = model.fit(x_train, y_train, epochs= 30, batch_size= 32)

plt.plot(range(0, 30), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

dataset = df[predicting_col]
dataset = pd.DataFrame(dataset)

train = dataset.iloc[:train_size , 0:1]
test = dataset.iloc[train_size: , 0:1]
test['Predictions'] = predictions

plt.figure(figsize= (16, 6))
plt.title('Price Prediction', fontsize= 18)
plt.xlabel('Date', fontsize= 18)
plt.ylabel('Price', fontsize= 18)
plt.plot(train[predicting_col], linewidth= 3)
plt.plot(test[predicting_col], linewidth= 3)
plt.plot(test["Predictions"], linewidth= 3)
plt.legend(['Train', 'Test', 'Predictions'])

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

# Get Prediction
predictions = model.predict(x_test)

predictions.shape

#inverse predictions scaling
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean( y_test - predictions )**2)#.round(2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

RMSE_scores["BiLSTM"] = RMSE
MAE_scores["BiLSTM"] = MAE

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})
preds_acts

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

"""##better parameters BiLSTM"""

#Compile model
model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=0.01),loss="mse")

"""also changed batch_size here"""

history = model.fit(x_train, y_train, epochs= 50, batch_size= 8)

plt.plot(range(0, 50), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

#inverse predictions scaling
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean( y_test - predictions )**2)#.round(2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

RMSE_scores["BiLSTM_new"] = RMSE
MAE_scores["BiLSTM_new"] = MAE

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

"""##stacked LSTM"""

# expected input data shape: (batch_size, timesteps, data_dim)
model = Sequential()
model.add(LSTM(50, return_sequences=True,
               input_shape=(x_train.shape[1], 1)))  # returns a sequence of vectors of dimension 50
model.add(LSTM(50, return_sequences=True))  # returns a sequence of vectors of dimension 50
model.add(LSTM(50))  # return a single vector of dimension 50
model.add(Dense(10))
model.add(Dense(1, activation='softmax'))

#Compile model
model.compile(optimizer='adam',loss="mse")

history = model.fit(x_train, y_train, epochs= 50, batch_size= 32)

plt.plot(range(0, 50), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

#inverse predictions scaling
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean( y_test - predictions )**2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

# RMSE_scores["stacked_LSTM"] = RMSE
# MAE_scores["stacked_LSTM"] = MAE

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

"""#Scores

##overall
"""

RMSE_scores["ARIMA"] = 2.29323403148108
MAE_scores["ARIMA"] = 1.87540593656118

RMSE_scores["ETS"] = 6.210656
MAE_scores["ETS"] = 5.670696

import matplotlib.pyplot as plt

plt.bar(list(RMSE_scores.keys()), RMSE_scores.values(), color='g')
plt.show()

plt.bar(list(MAE_scores.keys()), MAE_scores.values(), color='y')
plt.show()

print(RMSE_scores)
print(MAE_scores)

RMSE_nn_scores = {'LSTM': 0.7073377724546014, 'another_LSTM': 0.3868903279147856, 'GRU': 0.5301496111401538, 'BiLSTM': 0.3130759938892126, 'BiLSTM_new': 0.1923078242906394}
MAE_nn_scores = {'LSTM': 1.270454746418442, 'another_LSTM': 1.2013823991859895, 'GRU': 1.4046107692944079, 'BiLSTM': 1.17087439568378, 'BiLSTM_new': 1.217127285747219}

"""##RNNs"""

plt.bar(list(RMSE_nn_scores.keys()), RMSE_nn_scores.values(), color='g')
plt.show()

plt.bar(list(MAE_nn_scores.keys()), MAE_nn_scores.values(), color='g')
plt.show()

"""#INVFC_M"""

df = pd.read_csv('/content/INVFC_M.csv')

df.datum = pd.to_datetime(df.Date)
df.set_index('Date', inplace=True)

df

predicting_col='INVFC_M'

"""#decomposition"""

ts_decomposition = seasonal_decompose(x=df[predicting_col], model='multiplicative', period=12)
trend_estimate = ts_decomposition.trend
seasonal_estimate = ts_decomposition.seasonal
residual_estimate = ts_decomposition.resid

plt.figure(figsize=(15,5))
plt.plot(df[predicting_col], label='Original')
plt.legend()

plt.figure(figsize=(15,5))
plt.plot(trend_estimate, label='Trend')
plt.legend()

plt.figure(figsize=(15,5))
plt.plot(seasonal_estimate, label='Seasonal')
plt.legend()

plt.figure(figsize=(15,5))
plt.plot(residual_estimate, label='Residual')
plt.legend()

"""train test split"""

trend_estimate = trend_estimate.dropna()

trend_estimate

trend = pd.DataFrame({"INVFC_M" : trend_estimate})

trend

x_train, y_train, scaler, train_size, test_size, scaled_data = prepare_data(trend, predicting_col)

train_size

test_size

scaled_data

"""#Models"""

RMSE_scores = {}
MAE_scores = {}

"""##LSTM"""

model = Sequential([
    LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1)),
    LSTM(units=50, return_sequences=False),
    Dense(units=25),
    Dense(units=1)
])

model.compile(optimizer='adam', loss='mean_squared_error')
history = model.fit(x_train, y_train, epochs= 30, batch_size= 8)

plt.plot(range(0, 30), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

dataset = trend[predicting_col]
dataset = pd.DataFrame(dataset)

train = dataset.iloc[:train_size , 0:1]
test = dataset.iloc[train_size: , 0:1]
test['Predictions'] = predictions

plt.figure(figsize= (16, 6))
plt.title('Price Prediction', fontsize= 18)
plt.xlabel('Date', fontsize= 18)
plt.ylabel('Price', fontsize= 18)
plt.plot(train[predicting_col], linewidth= 3)
plt.plot(test[predicting_col], linewidth= 3)
plt.plot(test["Predictions"], linewidth= 3)
plt.legend(['Train', 'Test', 'Predictions'])

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

# Get Prediction
predictions = model.predict(x_test)

predictions.shape

#inverse predictions scaling
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean(y_test - predictions)**2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

RMSE_scores["LSTM"] = RMSE
MAE_scores["LSTM"] = MAE

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})
preds_acts

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

model = Sequential([
    LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1)),
    LSTM(units=50, return_sequences=False),
    Dense(units=25),
    Dense(units=1)
])

model.compile(optimizer='adam', loss='mean_squared_error')
history = model.fit(x_train, y_train, epochs= 30, batch_size= 8)

plt.plot(range(0, 30), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

dataset = trend[predicting_col]
dataset = pd.DataFrame(dataset)

train = dataset.iloc[:train_size , 0:1]
test = dataset.iloc[train_size: , 0:1]
test['Predictions'] = predictions

plt.figure(figsize= (16, 6))
plt.title('Price Prediction', fontsize= 18)
plt.xlabel('Date', fontsize= 18)
plt.ylabel('Price', fontsize= 18)
plt.plot(train[predicting_col], linewidth= 3)
plt.plot(test[predicting_col], linewidth= 3)
plt.plot(test["Predictions"], linewidth= 3)
plt.legend(['Train', 'Test', 'Predictions'])

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

# Get Prediction
predictions = model.predict(x_test)

predictions.shape

#inverse predictions scaling
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean(y_test - predictions)**2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

RMSE_scores["LSTM"] = RMSE
MAE_scores["LSTM"] = MAE

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})
preds_acts

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

"""##another LSTM"""

model = Sequential([
    LSTM(units=24, return_sequences=True, input_shape=(x_train.shape[1], 1)),
    LSTM(units=24, return_sequences=False),
    Dense(units=24),
    Dense(units=1)
])

model.compile(optimizer='adam', loss='mean_squared_error')
history = model.fit(x_train, y_train, epochs= 30, batch_size= 8)

plt.plot(range(0, 30), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

dataset = trend[predicting_col]
dataset = pd.DataFrame(dataset)

train = dataset.iloc[:train_size , 0:1]
test = dataset.iloc[train_size: , 0:1]
test['Predictions'] = predictions

plt.figure(figsize= (16, 6))
plt.title('Price Prediction', fontsize= 18)
plt.xlabel('Date', fontsize= 18)
plt.ylabel('Price', fontsize= 18)
plt.plot(train[predicting_col], linewidth= 3)
plt.plot(test[predicting_col], linewidth= 3)
plt.plot(test["Predictions"], linewidth= 3)
plt.legend(['Train', 'Test', 'Predictions'])

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

# Get Prediction
predictions = model.predict(x_test)

predictions.shape

#inverse predictions scaling
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean( y_test - predictions )**2)#.round(2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

RMSE_scores["another_LSTM"] = RMSE
MAE_scores["another_LSTM"] = MAE

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})
preds_acts

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

"""##GRU"""

# Create GRU model
def create_gru(units):
    model = Sequential()

    # Input layer
    model.add(layers.GRU(units = units, return_sequences = True,
    input_shape = [x_train.shape[1], x_train.shape[2]]))
    model.add(layers.Dropout(0.2))

    # Hidden layer
    model.add(layers.GRU(units = units))
    model.add(layers.Dropout(0.2))
    model.add(Dense(units = 1))

    #Compile model
    #model.compile(optimizer='adam',loss='mse')
    return model
model = create_gru(64)

model.compile(optimizer='adam', loss='mean_squared_error')
history = model.fit(x_train, y_train, epochs= 30, batch_size= 8)

plt.plot(range(0, 30), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

dataset = trend[predicting_col]
dataset = pd.DataFrame(dataset)

train = dataset.iloc[:train_size , 0:1]
test = dataset.iloc[train_size: , 0:1]
test['Predictions'] = predictions

plt.figure(figsize= (16, 6))
plt.title('Price Prediction', fontsize= 18)
plt.xlabel('Date', fontsize= 18)
plt.ylabel('Price', fontsize= 18)
plt.plot(train[predicting_col], linewidth= 3)
plt.plot(test[predicting_col], linewidth= 3)
plt.plot(test["Predictions"], linewidth= 3)
plt.legend(['Train', 'Test', 'Predictions'])

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

# Get Prediction
predictions = model.predict(x_test)

predictions.shape

#inverse predictions scaling
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean( y_test - predictions )**2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

RMSE_scores["GRU"] = RMSE
MAE_scores["GRU"] = MAE

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})
preds_acts

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

"""##BiLSTM

bidirectional LSTM
"""

# Create BiLSTM model
def create_bilstm(units):
  model = Sequential()

  # Input layer
  model.add(layers.Bidirectional(
              LSTM(units = units, return_sequences=True),
              input_shape=(x_train.shape[1], x_train.shape[2])))

  # Hidden layer
  model.add(layers.Bidirectional(LSTM(units = units)))
  model.add(Dense(1))

  return model

model = create_bilstm(64)

#Compile model
model.compile(optimizer="adam",loss="mse")

model.compile(optimizer='adam', loss='mean_squared_error')
history = model.fit(x_train, y_train, epochs= 30, batch_size= 8)

plt.plot(range(0, 30), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

dataset = trend[predicting_col]
dataset = pd.DataFrame(dataset)

train = dataset.iloc[:train_size , 0:1]
test = dataset.iloc[train_size: , 0:1]
test['Predictions'] = predictions

plt.figure(figsize= (16, 6))
plt.title('Price Prediction', fontsize= 18)
plt.xlabel('Date', fontsize= 18)
plt.ylabel('Price', fontsize= 18)
plt.plot(train[predicting_col], linewidth= 3)
plt.plot(test[predicting_col], linewidth= 3)
plt.plot(test["Predictions"], linewidth= 3)
plt.legend(['Train', 'Test', 'Predictions'])

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

# Get Prediction
predictions = model.predict(x_test)

predictions.shape

#inverse predictions scaling
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean( y_test - predictions )**2)#.round(2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

RMSE_scores["BiLSTM"] = RMSE
MAE_scores["BiLSTM"] = MAE

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})
preds_acts

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

"""##better parameters BiLSTM"""

#Compile model
model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=0.01),loss="mse")

"""also changed batch_size here"""

history = model.fit(x_train, y_train, epochs= 50, batch_size= 8)

plt.plot(range(0, 50), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

#inverse predictions scaling
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean( y_test - predictions )**2)#.round(2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

RMSE_scores["BiLSTM_new"] = RMSE
MAE_scores["BiLSTM_new"] = MAE

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

print(RMSE_scores)

print(MAE_scores)

rmse = {'LSTM': 6.646479143415132, 'another_LSTM': 6.675243946862646, 'GRU': 6.504253665984575, 'BiLSTM': 20.78328489273318, 'BiLSTM_new': 28.953437344990125}
mae = {'LSTM': 9.236336069258401, 'another_LSTM': 9.02345099878063, 'GRU': 10.261033541563286, 'BiLSTM': 20.972604063326767, 'BiLSTM_new': 28.953437344990125}


for i in rmse:
  print("Качество: \\\\")
  print("RMSE:", rmse[i], "\\\\")
  print("MAE:", mae[i], "\\\\")

"""##stacked LSTM"""

# expected input data shape: (batch_size, timesteps, data_dim)
model = Sequential()
model.add(LSTM(50, return_sequences=True,
               input_shape=(x_train.shape[1], 1)))  # returns a sequence of vectors of dimension 50
model.add(LSTM(50, return_sequences=True))  # returns a sequence of vectors of dimension 50
model.add(LSTM(50))  # return a single vector of dimension 50
model.add(Dense(10))
model.add(Dense(1, activation='softmax'))

#Compile model
model.compile(optimizer='adam',loss="mse")

history = model.fit(x_train, y_train, epochs= 50, batch_size= 32)

plt.plot(range(0, 50), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

#inverse predictions scaling
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean( y_test - predictions )**2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

# RMSE_scores["stacked_LSTM"] = RMSE
# MAE_scores["stacked_LSTM"] = MAE

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

"""#Scores

##overall
"""

RMSE_scores["ARIMA"] = 39.81417
MAE_scores["ARIMA"] = 28.28481

RMSE_scores["ETS"] = 19.65994
MAE_scores["ETS"] = 16.54448

import matplotlib.pyplot as plt

plt.bar(list(RMSE_scores.keys()), RMSE_scores.values(), color='g')
plt.show()

plt.bar(list(MAE_scores.keys()), MAE_scores.values(), color='y')
plt.show()

print(RMSE_scores)
print(MAE_scores)

RMSE_nn_scores = {'LSTM': 6.646479143415132, 'another_LSTM': 6.675243946862646, 'GRU': 6.504253665984575, 'BiLSTM': 20.78328489273318, 'BiLSTM_new': 28.953437344990125}
MAE_nn_scores = {'LSTM': 9.236336069258401, 'another_LSTM': 9.02345099878063, 'GRU': 10.261033541563286, 'BiLSTM': 20.972604063326767, 'BiLSTM_new': 28.953437344990125}

"""##RNNs"""

plt.bar(list(RMSE_nn_scores.keys()), RMSE_nn_scores.values(), color='g')
plt.show()

plt.bar(list(MAE_nn_scores.keys()), MAE_nn_scores.values(), color='g')
plt.show()



"""#CPI_M_CHI"""

df = pd.read_csv('/content/CPI_M_CHI.csv')

#df.Date = pd.to_datetime(df.Date)
df.set_index('Date', inplace=True)

df

predicting_col='CPI_M_CHI'

"""#decomposition"""

ts_decomposition = seasonal_decompose(x=df[predicting_col], model='multiplicative', period=12)
trend_estimate = ts_decomposition.trend
seasonal_estimate = ts_decomposition.seasonal
residual_estimate = ts_decomposition.resid

plt.figure(figsize=(15,5))
plt.plot(df[predicting_col], label='Original')
plt.legend()

plt.figure(figsize=(15,5))
plt.plot(trend_estimate, label='Trend')
plt.legend()

plt.figure(figsize=(15,5))
plt.plot(seasonal_estimate, label='Seasonal')
plt.legend()

plt.figure(figsize=(15,5))
plt.plot(residual_estimate, label='Residual')
plt.legend()

x_train, y_train, scaler, train_size, test_size, scaled_data = prepare_data(df, predicting_col)

train_size

test_size

scaled_data

"""#Models"""

RMSE_scores = {}
MAE_scores = {}

"""##LSTM"""

model = Sequential([
    LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1)),
    LSTM(units=50, return_sequences=False),
    Dense(units=25),
    Dense(units=1)
])

model.compile(optimizer='adam', loss='mean_squared_error')
history = model.fit(x_train, y_train, epochs= 30, batch_size= 8)

plt.plot(range(0, 30), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

dataset = df[predicting_col]
dataset = pd.DataFrame(dataset)

train = dataset.iloc[:train_size , 0:1]
test = dataset.iloc[train_size: , 0:1]
test['Predictions'] = predictions

plt.figure(figsize= (16, 6))
plt.title('Price Prediction', fontsize= 18)
plt.xlabel('Price index', fontsize= 18)
plt.ylabel('Price index', fontsize= 18)
plt.plot(train[predicting_col], linewidth= 3)
plt.plot(test[predicting_col], linewidth= 3)
plt.plot(test["Predictions"], linewidth= 3)
plt.legend(['Train', 'Test', 'Predictions'])

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

# Get Prediction
predictions = model.predict(x_test)

predictions.shape

#inverse predictions scaling
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean(y_test - predictions)**2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

RMSE_scores["LSTM"] = RMSE
MAE_scores["LSTM"] = MAE

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})
preds_acts

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

"""##another LSTM"""

model = Sequential([
    LSTM(units=24, return_sequences=True, input_shape=(x_train.shape[1], 1)),
    LSTM(units=24, return_sequences=False),
    Dense(units=24),
    Dense(units=1)
])

model.compile(optimizer='adam', loss='mean_squared_error')
history = model.fit(x_train, y_train, epochs= 30, batch_size= 8)

plt.plot(range(0, 30), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

dataset = df[predicting_col]
dataset = pd.DataFrame(dataset)

train = dataset.iloc[:train_size , 0:1]
test = dataset.iloc[train_size: , 0:1]
test['Predictions'] = predictions

plt.figure(figsize= (16, 6))
plt.title('Price Prediction', fontsize= 18)
plt.xlabel('Date', fontsize= 18)
plt.ylabel('Price', fontsize= 18)
plt.plot(train[predicting_col], linewidth= 3)
plt.plot(test[predicting_col], linewidth= 3)
plt.plot(test["Predictions"], linewidth= 3)
plt.legend(['Train', 'Test', 'Predictions'])

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

# Get Prediction
predictions = model.predict(x_test)

predictions.shape

#inverse predictions scaling
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean( y_test - predictions )**2)#.round(2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

RMSE_scores["another_LSTM"] = RMSE
MAE_scores["another_LSTM"] = MAE

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})
preds_acts

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

"""##GRU"""

# Create GRU model
def create_gru(units):
    model = Sequential()

    # Input layer
    model.add(layers.GRU(units = units, return_sequences = True,
    input_shape = [x_train.shape[1], x_train.shape[2]]))
    model.add(layers.Dropout(0.2))

    # Hidden layer
    model.add(layers.GRU(units = units))
    model.add(layers.Dropout(0.2))
    model.add(Dense(units = 1))

    #Compile model
    #model.compile(optimizer='adam',loss='mse')
    return model
model = create_gru(64)

model.compile(optimizer='adam', loss='mean_squared_error')
history = model.fit(x_train, y_train, epochs= 30, batch_size= 8)

plt.plot(range(0, 30), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

dataset = df[predicting_col]
dataset = pd.DataFrame(dataset)

train = dataset.iloc[:train_size , 0:1]
test = dataset.iloc[train_size: , 0:1]
test['Predictions'] = predictions

plt.figure(figsize= (16, 6))
plt.title('Price Prediction', fontsize= 18)
plt.xlabel('Date', fontsize= 18)
plt.ylabel('Price', fontsize= 18)
plt.plot(train[predicting_col], linewidth= 3)
plt.plot(test[predicting_col], linewidth= 3)
plt.plot(test["Predictions"], linewidth= 3)
plt.legend(['Train', 'Test', 'Predictions'])

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

# Get Prediction
predictions = model.predict(x_test)

predictions.shape

#inverse predictions scaling
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean( y_test - predictions )**2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

RMSE_scores["GRU"] = RMSE
MAE_scores["GRU"] = MAE

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})
preds_acts

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

"""##BiLSTM

bidirectional LSTM
"""

# Create BiLSTM model
def create_bilstm(units):
  model = Sequential()

  # Input layer
  model.add(layers.Bidirectional(
              LSTM(units = units, return_sequences=True),
              input_shape=(x_train.shape[1], x_train.shape[2])))

  # Hidden layer
  model.add(layers.Bidirectional(LSTM(units = units)))
  model.add(Dense(1))

  return model

model = create_bilstm(64)

#Compile model
model.compile(optimizer="adam",loss="mse")

model.compile(optimizer='adam', loss='mean_squared_error')
history = model.fit(x_train, y_train, epochs= 30, batch_size= 8)

plt.plot(range(0, 30), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

dataset = df[predicting_col]
dataset = pd.DataFrame(dataset)

train = dataset.iloc[:train_size , 0:1]
test = dataset.iloc[train_size: , 0:1]
test['Predictions'] = predictions

plt.figure(figsize= (16, 6))
plt.title('Price Prediction', fontsize= 18)
plt.xlabel('Date', fontsize= 18)
plt.ylabel('Price', fontsize= 18)
plt.plot(train[predicting_col], linewidth= 3)
plt.plot(test[predicting_col], linewidth= 3)
plt.plot(test["Predictions"], linewidth= 3)
plt.legend(['Train', 'Test', 'Predictions'])

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})

plt.figure(figsize = (16, 6))
plt.plot(preds_acts['Predictions'])
plt.plot(preds_acts['Actuals'])
plt.legend(['Predictions', 'Actuals'])
plt.show()

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

# Get Prediction
predictions = model.predict(x_test)

predictions.shape

#inverse predictions scaling
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean( y_test - predictions )**2)#.round(2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

RMSE_scores["BiLSTM"] = RMSE
MAE_scores["BiLSTM"] = MAE

preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})
preds_acts

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

"""##better parameters BiLSTM"""

#Compile model
model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=0.01),loss="mse")

"""also changed batch_size here"""

history = model.fit(x_train, y_train, epochs= 50, batch_size= 8)

plt.plot(range(0, 50), history.history['loss'], c='r')
plt.show()

x_test, y_test = generate_forecast(scaled_data, train_size)

y_test = scaler.inverse_transform(y_test)
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

# Creating a testing set with 60 time-steps and 1 output
time_steps = 60
test_data = scaled_data[train_size - time_steps:, :]

x_test = []
y_test = []
n_cols = 1

for i in range(time_steps, len(test_data)):
    x_test.append(test_data[i-time_steps:i, 0:n_cols])
    y_test.append(test_data[i, 0:n_cols])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))

#inverse predictions scaling
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)
predictions.shape

#inverse y_test scaling
y_test = scaler.inverse_transform(y_test)
RMSE = np.sqrt(np.mean( y_test - predictions )**2)#.round(2)
RMSE

MAE = np.mean(abs(y_test - predictions))
MAE

RMSE_scores["BiLSTM_new"] = RMSE
MAE_scores["BiLSTM_new"] = MAE

plt.plot(preds_acts.index, preds_acts.Predictions, c='r')
plt.plot(preds_acts.index, preds_acts.Actuals, c='b')
plt.show()

print(RMSE_scores)

print(MAE_scores)

RMSE_scores = {'LSTM': 0.49607112154047517, 'another_LSTM': 0.024479951249792433, 'GRU': 0.4663050387768033, 'BiLSTM': 0.36624833776595767, 'BiLSTM_new': 1.5016154674773525}
MAE_scores = {'LSTM': 0.6382722245885967, 'another_LSTM': 0.3500500455815739, 'GRU': 0.6089597499116934, 'BiLSTM': 0.467908753740027, 'BiLSTM_new': 1.5016154674773525}


for i in rmse:
  print("Качество: \\\\")
  print("RMSE:", rmse[i], "\\\\")
  print("MAE:", mae[i], "\\\\")

"""##Scores

##overall
"""

RMSE_scores["ARIMA"] =  2.826317
MAE_scores["ARIMA"] = 2.443597

RMSE_scores["ETS"] = 2.800738
MAE_scores["ETS"] = 2.770085

import matplotlib.pyplot as plt

plt.bar(list(RMSE_scores.keys()), RMSE_scores.values(), color='g')
plt.show()

plt.bar(list(MAE_scores.keys()), MAE_scores.values(), color='y')
plt.show()

print(RMSE_scores)
print(MAE_scores)

RMSE_nn_scores = {'LSTM': 0.49607112154047517, 'another_LSTM': 0.024479951249792433, 'GRU': 0.4663050387768033, 'BiLSTM': 0.36624833776595767, 'BiLSTM_new': 1.5016154674773525}
MAE_nn_scores = {'LSTM': 0.6382722245885967, 'another_LSTM': 0.3500500455815739, 'GRU': 0.6089597499116934, 'BiLSTM': 0.467908753740027, 'BiLSTM_new': 1.5016154674773525}

"""##RNNs"""

plt.bar(list(RMSE_nn_scores.keys()), RMSE_nn_scores.values(), color='g')
plt.show()

plt.bar(list(MAE_nn_scores.keys()), MAE_nn_scores.values(), color='g')
plt.show()